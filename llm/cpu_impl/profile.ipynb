{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "sys.path.insert(2, \"../..\")\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd;\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "from huggingface_hub import login\n",
    "import time\n",
    "import os\n",
    "\n",
    "from patch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\" # cpu or cuda\n",
    "METHOD = \"Naive\" # RSR or Naive\n",
    "MODEL = \"tiiuae/Falcon3-3B-Instruct-1.58bit\" # [HF1BitLLM/Llama3-8B-1.58-100B-tokens, tiiuae/Falcon3-3B-Instruct-1.58bit]\n",
    "TOKENIZER = \"tiiuae/Falcon3-3B-Instruct-1.58bit\" # [meta-llama/Meta-Llama-3-8B-Instruct, tiiuae/Falcon3-3B-Instruct-1.58bit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this cell if you want to see the 'Optimized Standard Inference'\n",
    "apply_patch(method=METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  False\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == \"cpu\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "    \n",
    "os.environ[\"HF_TOKEN\"]=\"YOUR TOKEN HERE\"\n",
    "print(\"cuda available? \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_Quantizer: <transformers.quantizers.quantizer_bitnet.BitNetHfQuantizer object at 0x7fb23a646380>\n",
      "** hf_quantizer.preprocess_model\n",
      "** hf_quantizer.postprocess_model\n",
      "Building tensors: 285 / 224\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74a52f1084b45659af2a462a32c8d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/365k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412e0ba2d0d0454e836f59f6c1180f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc20bcf6b5af4cdd97f1cafe6d230db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL, \n",
    "                                         device_map=DEVICE, \n",
    "                                         torch_dtype=torch.bfloat16).to(device)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(TOKENIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt, max_length=20, tokens_to_generate=1):\n",
    "    start_time = time.time()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)#.cuda()\n",
    "    output = model.generate(input_ids, max_length=max_length, do_sample=False, max_new_tokens=tokens_to_generate);\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True);\n",
    "    print(f\"{prompt} --> {generated_text}\")\n",
    "    return {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"response\": generated_text,\n",
    "        \"device\": DEVICE,\n",
    "        \"method\": METHOD\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who wrote Romeo and Juliet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is 2 + 2?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in the solar system?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 q\n",
       "0                   What is the capital of France?\n",
       "1                      Who wrote Romeo and Juliet?\n",
       "2                                   What is 2 + 2?\n",
       "3  What is the largest planet in the solar system?\n",
       "4                       Who painted the Mona Lisa?"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/questions_df.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:00<09:06, 60.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France? --> What is the capital of France?\n",
      "\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:53<07:26, 55.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who wrote Romeo and Juliet? --> Who wrote Romeo and Juliet?\n",
      "\n",
      "Input ID: torch.Size([1, 9]), Input Embed:torch.Size([1, 9, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:06<07:28, 64.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 2 + 2? --> What is 2 + 2?\n",
      "\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [04:21<10:10, 87.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, question \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36minfer\u001b[0;34m(prompt, max_length, tokens_to_generate)\u001b[0m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;66;03m#.cuda()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens_to_generate\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      5\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m);\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:3254\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3254\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:844\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 844\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    859\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:602\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    591\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    592\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m         position_embeddings,\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:350\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    349\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 350\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    353\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:186\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 186\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RSR/llm/cpu_impl/../patch.py:83\u001b[0m, in \u001b[0;36mrsr_forward\u001b[0;34m(self, input, method)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbitnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unpack_weights\n\u001b[1;32m     82\u001b[0m input_quant, input_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_quant(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m y \u001b[38;5;241m=\u001b[39m (input_quant\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m@\u001b[39m \u001b[43munpack_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     84\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quant_process(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_scale, input_scale)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    469\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    470\u001b[0m     )\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/transformers/integrations/bitnet.py:57\u001b[0m, in \u001b[0;36munpack_weights\u001b[0;34m(packed, dtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m         packed[: (end \u001b[38;5;241m-\u001b[39m start)] \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m unpacked[start:end] \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m packed\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mcompile\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21munpack_weights\u001b[39m(packed: torch\u001b[38;5;241m.\u001b[39mTensor, dtype: torch\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Unpacks a tensor of quantized weights that were stored in a packed format using 2 bits per value.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    this by subtracting 1 to restore the original ternary values.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     packed_shape \u001b[38;5;241m=\u001b[39m packed\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1100\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.forward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   1098\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(params_flat)\n\u001b[1;32m   1099\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(runtime_args)\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:321\u001b[0m, in \u001b[0;36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n\u001b[1;32m    320\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 321\u001b[0m     all_outs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_at_runtime_with_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiled_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteal_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py:124\u001b[0m, in \u001b[0;36mcall_func_at_runtime_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m         out \u001b[38;5;241m=\u001b[39m normalize_as_list(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt take boxed arguments. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m         )\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:667\u001b[0m, in \u001b[0;36mEffectTokensWrapper.post_compile.<locals>.inner_fn\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    664\u001b[0m     args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m num_tokens), \u001b[38;5;241m*\u001b[39margs]\n\u001b[1;32m    665\u001b[0m     old_args\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m--> 667\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# Inductor cache DummyModule can return None\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:488\u001b[0m, in \u001b[0;36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[0;34m(runtime_args)\u001b[0m\n\u001b[1;32m    481\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functionalized_rng_runtime_epilogue(\n\u001b[1;32m    482\u001b[0m         runtime_metadata,\n\u001b[1;32m    483\u001b[0m         out,\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[1;32m    485\u001b[0m         runtime_metadata\u001b[38;5;241m.\u001b[39mnum_forward_returns,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RSR/.venv/lib/python3.10/site-packages/torch/_inductor/codecache.py:1478\u001b[0m, in \u001b[0;36mCompiledFxGraph.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_callable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/tmp/torchinductor_mohsen/uo/cuoprfr42sgqeeegxtdlklh5wi7h62u5qd5owtkrs66z55w4ihxe.py:223\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    221\u001b[0m assert_size_stride(arg3_1, (s0, s1, s2), (s1\u001b[38;5;241m*\u001b[39ms2, s2, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    222\u001b[0m buf1 \u001b[38;5;241m=\u001b[39m empty_strided_cpu((\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39ms0, s1, s2), (s1\u001b[38;5;241m*\u001b[39ms2, s2, \u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m--> 223\u001b[0m \u001b[43mcpp_fused___rshift____to_copy_bitwise_and_sub_zeros_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg3_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arg3_1\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (buf1, )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i, question in tqdm.tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    result.append(infer(prompt=question[\"q\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv(\"./report/RSR_Questions_Falcon10.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What kind of music is anthems for worship?',\n",
       " \"what was billy walton's football position?\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(2)\n",
    "\n",
    "lines = []\n",
    "with open(\"../datasets/annotated_wd_data_test.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    lines = random.sample(lines, 20)\n",
    "\n",
    "lines = [l.split(\"\\t\")[-1].strip() for l in lines]\n",
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: torch.Size([1, 9]), Input Embed:torch.Size([1, 9, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:19<06:17, 19.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of music is anthems for worship? --> What kind of music is anthems for worship?\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:41<06:14, 20.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what was billy walton's football position? --> what was billy walton's football position?\n",
      "\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:02<05:58, 21.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which footballer was born in canton of nidwalden --> which footballer was born in canton of nidwalden \n",
      "Input ID: torch.Size([1, 11]), Input Embed:torch.Size([1, 11, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:26<05:51, 21.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which city and country was toni branca born in --> Which city and country was toni branca born in?\n",
      "Input ID: torch.Size([1, 8]), Input Embed:torch.Size([1, 8, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:44<05:08, 20.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is a politician born in gloucester --> Who is a politician born in gloucestershire\n",
      "Input ID: torch.Size([1, 9]), Input Embed:torch.Size([1, 9, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:03<04:42, 20.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What genre of film is ram-avtar --> What genre of film is ram-avtar?\n",
      "Input ID: torch.Size([1, 17]), Input Embed:torch.Size([1, 17, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:37<05:21, 24.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what did amir-abbas hoveyda die as a result of? --> what did amir-abbas hoveyda die as a result of?\n",
      "\n",
      "Input ID: torch.Size([1, 5]), Input Embed:torch.Size([1, 5, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:49<04:09, 20.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is largemouth bass --> what is largemouth bass?\n",
      "Input ID: torch.Size([1, 13]), Input Embed:torch.Size([1, 13, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [03:16<04:08, 22.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who was a military personnel involved in the battle of fredericksburg --> who was a military personnel involved in the battle of fredericksburg.\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:37<03:40, 22.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what's a movie in the india netflix genre --> what's a movie in the india netflix genre?\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:58<03:16, 21.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name a famous Australian singer known for pop music? --> Name a famous Australian singer known for pop music?\n",
      "\n",
      "Input ID: torch.Size([1, 8]), Input Embed:torch.Size([1, 8, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [04:16<02:44, 20.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the record label of afi --> what is the record label of afi k\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:37<02:25, 20.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who was in charge of story on jumanji --> who was in charge of story on jumanji and\n",
      "Input ID: torch.Size([1, 12]), Input Embed:torch.Size([1, 12, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [05:02<02:12, 22.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What country did the battle of lechfeld take place in --> What country did the battle of lechfeld take place in?\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [05:23<01:48, 21.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is elizabeth couchman's gender? --> what is elizabeth couchman's gender?\n",
      "\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:37<01:17, 19.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what kind of book is night --> what kind of book is night and\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:51<00:53, 17.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who composed run for your life --> who composed run for your life.\n",
      "Input ID: torch.Size([1, 14]), Input Embed:torch.Size([1, 14, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [06:19<00:41, 20.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the former Justice of Supreme Court of Pakistan born in mumbai --> Who is the former Justice of Supreme Court of Pakistan born in mumbai?\n",
      "Input ID: torch.Size([1, 8]), Input Embed:torch.Size([1, 8, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:37<00:19, 19.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which artist is considered an indie rock artist --> which artist is considered an indie rock artist?\n",
      "Input ID: torch.Size([1, 9]), Input Embed:torch.Size([1, 9, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:56<00:00, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what label is the the delmore brothers under --> what label is the the delmore brothers under?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for row in tqdm.tqdm(lines):\n",
    "    result.append(infer(prompt=row, max_length=20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(result).to_csv(\"./report/RSR_SimpleQuestions_Falcon.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREC QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>label-fine</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>How far is it from Denver to Aspen ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>What county is Modesto , California in ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>Who was Galileo ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>What is an atom ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>When did Hawaii become a state ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label-coarse  label-fine                                      text\n",
       "0             4          40      How far is it from Denver to Aspen ?\n",
       "1             5          21  What county is Modesto , California in ?\n",
       "2             3          12                         Who was Galileo ?\n",
       "3             0           7                         What is an atom ?\n",
       "4             4           8          When did Hawaii become a state ?"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/trecqa_test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:14<04:31, 14.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When was Hiroshima bombed ? --> When was Hiroshima bombed?\n",
      "\n",
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:30<04:34, 15.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much does water weigh ? --> How much does water weigh?\n",
      "\n",
      "Input ID: torch.Size([1, 5]), Input Embed:torch.Size([1, 5, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:42<03:55, 13.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are triglycerides ? --> What are triglycerides?\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:56<03:41, 13.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are spider veins ? --> What are spider veins?\n",
      "Input ID: torch.Size([1, 11]), Input Embed:torch.Size([1, 11, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:19<04:17, 17.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which country gave New York the Statue of Liberty ? --> Which country gave New York the Statue of Liberty?\n",
      "\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:33<03:45, 16.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is cerebral palsy ? --> What is cerebral palsy?\n",
      "Input ID: torch.Size([1, 8]), Input Embed:torch.Size([1, 8, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:50<03:35, 16.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Persia ? --> What is the capital of Persia?\n",
      "\n",
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:06<03:16, 16.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are the Rocky Mountains ? --> Where are the Rocky Mountains?\n",
      "\n",
      "Input ID: torch.Size([1, 10]), Input Embed:torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:27<03:16, 17.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the criterion for being legally blind ? --> What is the criterion for being legally blind?\n",
      "Input ID: torch.Size([1, 23]), Input Embed:torch.Size([1, 23, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:12<04:20, 26.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The U.S. Department of Treasury first issued paper currency for the U.S. during which war ? --> The U.S. Department of Treasury first issued paper currency for the U.S. during which war?\n",
      "\n",
      "Input ID: torch.Size([1, 5]), Input Embed:torch.Size([1, 5, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:24<03:15, 21.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is TMJ ? --> What is TMJ?\n",
      "Input ID: torch.Size([1, 12]), Input Embed:torch.Size([1, 12, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:48<03:01, 22.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What state has the least amount of rain per year ? --> What state has the least amount of rain per year?\n",
      "\n",
      "Input ID: torch.Size([1, 5]), Input Embed:torch.Size([1, 5, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:01<02:16, 19.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is Perth ? --> Where is Perth?\n",
      "\n",
      "Input ID: torch.Size([1, 9]), Input Embed:torch.Size([1, 9, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:20<01:56, 19.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a newborn kangaroo ? --> What do you call a newborn kangaroo? A\n",
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:36<01:31, 18.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is the Savannah River ? --> Where is the Savannah River?\n",
      "Input ID: torch.Size([1, 8]), Input Embed:torch.Size([1, 8, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [04:53<01:12, 18.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the birthstone for June ? --> What is the birthstone for June?\n",
      "\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:07<00:50, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is an ulcer ? --> What is an ulcer?\n",
      "Input ID: torch.Size([1, 6]), Input Embed:torch.Size([1, 6, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:21<00:31, 15.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is strep throat ? --> What is strep throat?\n",
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [05:37<00:15, 15.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Both `max_new_tokens` (=1) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are the National Archives ? --> Where are the National Archives?\n",
      "\n",
      "Input ID: torch.Size([1, 7]), Input Embed:torch.Size([1, 7, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:53<00:00, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is a German philosopher ? --> Who is a German philosopher?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in tqdm.tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    result.append(infer(prompt=row[\"text\"], max_length=20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv(\"./report/RSR_Trec_Falcon.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20.000000\n",
       "mean     326.410688\n",
       "std      151.095275\n",
       "min      207.788311\n",
       "25%      248.496185\n",
       "50%      287.492259\n",
       "75%      336.850179\n",
       "max      884.360934\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./report/Naive_Trec_Falcon10.csv\", index_col=False)[\"time\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from your table\n",
    "datasets = ['Short Questions', 'SimpleQuestion', 'TrecQA']\n",
    "# Falcon3-10B-Instruct-1.58bit\n",
    "# standard_times = [336.6, 391.8, 326.4]\n",
    "# rsr_times = [68.5, 78.4, 65.3]\n",
    "\n",
    "# falcon\n",
    "# standard_times = [96.9, 101.4, 72.4]\n",
    "# rsr_times = [18.5, 20.8, 17.6]\n",
    "\n",
    "# Llama3-8B-1.58-100B-tokens\n",
    "standard_times = [336.7, 391.8, 326.4]\n",
    "rsr_times = [68.5, 78.5, 65.4]\n",
    "\n",
    "# Calculate speedup factors\n",
    "speedup_factors = [std / rsr for std, rsr in zip(standard_times, rsr_times)]\n",
    "\n",
    "# Bar positions and width\n",
    "x = np.arange(len(datasets))\n",
    "bar_width = 0.4\n",
    "\n",
    "# Plot bars for running times\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "bars1 = ax.bar(x - bar_width/2, standard_times, bar_width, label='Standard', alpha=0.7, color='blue')\n",
    "bars2 = ax.bar(x + bar_width/2, rsr_times, bar_width, label='RSR', alpha=0.7, color='orange')\n",
    "\n",
    "# Configure the y-axis\n",
    "ax.set_ylabel('Running Time (s)', fontsize=17)\n",
    "ax.set_title('Average Inference Time for Llama3-8B-1.58bit', fontsize=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets, fontsize=17)\n",
    "ax.legend(loc='upper right', fontsize=18)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add data labels to bars\n",
    "for i, bar in enumerate(bars1):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 10,\n",
    "        f'{bar.get_height():.1f} ({speedup_factors[i]:.2f}x)',\n",
    "        ha='center',\n",
    "        fontsize=16,\n",
    "    )\n",
    "for bar in bars2:\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 10,\n",
    "        f'{bar.get_height():.1f}',\n",
    "        ha='center',\n",
    "        fontsize=16\n",
    "    )\n",
    "\n",
    "# Adjust y-axis limits for better visualization\n",
    "ax.set_ylim(0, max(standard_times) + 50)  # Add some padding to the top\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"time_compare_llama.eps\", format=\"eps\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
